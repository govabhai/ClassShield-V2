{% extends "base.html" %}

{% block content %}
<div class="content-wrapper">
    <h2 class="mb-4"><i class="bi bi-camera-video"></i> Demo Video Plan</h2>
    
    <div class="alert alert-info">
        <i class="bi bi-film"></i> This 2-minute demo video showcases ClassShield's key features and ethical AI implementation with Llama Vision (Groq) for judging evaluation.
    </div>

    <h4 class="mt-4">Video Structure (2:00 Total)</h4>

    <div class="card mb-3">
        <div class="card-body">
            <h5><i class="bi bi-1-circle text-primary"></i> Introduction (0:00 - 0:20) - 20 seconds</h5>
            
            <p><strong>Visual:</strong> Homepage with logo and project title</p>
            <p><strong>Voiceover Script:</strong></p>
            <blockquote class="border-start border-primary ps-3">
                "Welcome to ClassShield, a school content safety system prototype designed with ethical AI principles and powered by Llama Vision. This demo showcases how AI can assist in protecting students while prioritizing privacy, transparency, and human oversight. Let's see how it works."
            </blockquote>
            
            <p><strong>On-Screen Text:</strong></p>
            <ul>
                <li>ClassShield V2</li>
                <li>Vision Analysis powered by Llama Vision (Groq)</li>
                <li>No Auto-Delete | Human Review Required | Privacy First</li>
            </ul>
        </div>
    </div>

    <div class="card mb-3">
        <div class="card-body">
            <h5><i class="bi bi-2-circle text-success"></i> Upload & Scan Demo (0:20 - 0:50) - 30 seconds</h5>
            
            <p><strong>Visual:</strong> Upload page with live scanning demonstration</p>
            <p><strong>Voiceover Script:</strong></p>
            <blockquote class="border-start border-success ps-3">
                "The system uses three layers of detection: a local NudeNet model, Sightengine cloud API fallback, and a basic heuristic. Watch as we upload a test image. The system scans in seconds, providing a safety decision with full transparency about the methods used and confidence scores."
            </blockquote>
            
            <p><strong>Actions to Show:</strong></p>
            <ul>
                <li>Click upload area</li>
                <li>Select a safe test image (beach photo)</li>
                <li>Click "Scan Image" button</li>
                <li>Show results appearing with decision badge</li>
                <li>Highlight confidence scores and evidence panel</li>
            </ul>
        </div>
    </div>

    <div class="card mb-3">
        <div class="card-body">
            <h5><i class="bi bi-3-circle text-info"></i> Explainability Feature (0:50 - 1:20) - 30 seconds</h5>
            
            <p><strong>Visual:</strong> Scan results page with explainability box expanded</p>
            <p><strong>Voiceover Script:</strong></p>
            <blockquote class="border-start border-info ps-3">
                "Every decision is fully explainable. The system shows which detection methods were used, the confidence scores from each model, and the specific thresholds that were applied. This transparency ensures accountability and helps administrators understand why content was flagged. Notice how the system provides both the AI's assessment and clear reasoning."
            </blockquote>
            
            <p><strong>Visual Highlights:</strong></p>
            <ul>
                <li>Point to "Methods Used" section</li>
                <li>Highlight confidence score bars</li>
                <li>Show threshold information</li>
                <li>Point to recommended action</li>
            </ul>
        </div>
    </div>

    <div class="card mb-3">
        <div class="card-body">
            <h5><i class="bi bi-4-circle text-warning"></i> Admin Review Dashboard (1:20 - 1:50) - 30 seconds</h5>
            
            <p><strong>Visual:</strong> Admin dashboard showing flagged items queue</p>
            <p><strong>Voiceover Script:</strong></p>
            <blockquote class="border-start border-warning ps-3">
                "Flagged content goes to the admin review dashboard where trained staff make final decisions. The system never auto-deletes. Administrators see all evidence, can approve or reject items, and their actions are logged for accountability. This human-in-the-loop approach prevents false positives from causing harm while maintaining student safety."
            </blockquote>
            
            <p><strong>Actions to Show:</strong></p>
            <ul>
                <li>Navigate to Admin Dashboard</li>
                <li>Show statistics (flagged count, pending, approved, rejected)</li>
                <li>Scroll through flagged items queue</li>
                <li>Expand one item to show full evidence</li>
                <li>Demonstrate approve/reject buttons</li>
                <li>Show audit log briefly</li>
            </ul>
        </div>
    </div>

    <div class="card mb-3">
        <div class="card-body">
            <h5><i class="bi bi-5-circle text-danger"></i> Closing (1:50 - 2:00) - 10 seconds</h5>
            
            <p><strong>Visual:</strong> Montage of policy pages (Ethical AI, Privacy, Bias Testing)</p>
            <p><strong>Voiceover Script:</strong></p>
            <blockquote class="border-start border-danger ps-3">
                "ClassShield, powered by AnveshAI, demonstrates responsible AI implementation with comprehensive ethical policies, bias testing, and privacy guarantees. Technology supporting humans, not replacing them. Thank you."
            </blockquote>
            
            <p><strong>On-Screen Text:</strong></p>
            <ul>
                <li>✓ Ethical AI Policy</li>
                <li>✓ Bias Testing Complete</li>
                <li>✓ Privacy First Design</li>
                <li>✓ Full Documentation</li>
            </ul>
        </div>
    </div>

    <h4 class="mt-4">Technical Production Notes</h4>

    <div class="card mb-3">
        <div class="card-body">
            <h5>Recording Setup</h5>
            <ul>
                <li><strong>Screen Recording:</strong> Use OBS Studio or similar at 1920x1080 resolution</li>
                <li><strong>Audio:</strong> Clear voiceover using quality microphone (Blue Yeti or similar)</li>
                <li><strong>Browser:</strong> Chrome with extensions disabled for clean UI</li>
                <li><strong>Cursor:</strong> Use cursor highlight plugin for visibility</li>
                <li><strong>Pacing:</strong> Slow, deliberate cursor movements</li>
            </ul>
        </div>
    </div>

    <div class="card mb-3">
        <div class="card-body">
            <h5>Test Images to Prepare</h5>
            <ul>
                <li><strong>Safe Image:</strong> Family beach photo (to show green "safe" result)</li>
                <li><strong>Suspect Image:</strong> Athletic/sports photo (to show yellow "suspect" result)</li>
                <li><strong>Demonstration Images:</strong> Already scanned items in admin queue</li>
            </ul>
            <p class="text-muted small">Note: Use stock photos or personal photos with permission. Never use actual inappropriate content.</p>
        </div>
    </div>

    <div class="card mb-3">
        <div class="card-body">
            <h5>Editing Checklist</h5>
            <ul class="list-group list-group-flush">
                <li class="list-group-item">
                    <input type="checkbox" disabled> Cut any loading delays or slow moments
                </li>
                <li class="list-group-item">
                    <input type="checkbox" disabled> Add background music (subtle, royalty-free)
                </li>
                <li class="list-group-item">
                    <input type="checkbox" disabled> Add smooth transitions between scenes
                </li>
                <li class="list-group-item">
                    <input type="checkbox" disabled> Highlight important UI elements with zoom or arrows
                </li>
                <li class="list-group-item">
                    <input type="checkbox" disabled> Add text overlays for key points
                </li>
                <li class="list-group-item">
                    <input type="checkbox" disabled> Ensure total runtime is 1:55-2:00
                </li>
                <li class="list-group-item">
                    <input type="checkbox" disabled> Export at 1080p, 30fps, H.264
                </li>
            </ul>
        </div>
    </div>

    <h4 class="mt-4">Alternative: Presentation Slides</h4>
    
    <div class="card mb-3">
        <div class="card-body">
            <p>If live demo is preferred, prepare these slides:</p>
            <ol>
                <li><strong>Title Slide:</strong> Project name, your name, date</li>
                <li><strong>Problem Statement:</strong> Why school content safety matters</li>
                <li><strong>Solution Overview:</strong> Three-tier detection, human review</li>
                <li><strong>Live Demo:</strong> Upload → Scan → Results (2 examples)</li>
                <li><strong>Explainability:</strong> Show evidence and reasoning</li>
                <li><strong>Admin Dashboard:</strong> Review workflow demonstration</li>
                <li><strong>Ethical AI Features:</strong> Privacy, bias testing, transparency</li>
                <li><strong>Impact & Conclusion:</strong> Benefits and responsible implementation</li>
            </ol>
        </div>
    </div>

    <h4 class="mt-4">Judging Q&A Preparation</h4>
    
    <div class="card mb-3">
        <div class="card-body">
            <p><strong>Anticipated Questions & Answers:</strong></p>
            
            <h6 class="mt-3">Q: How accurate is the system?</h6>
            <p>A: In testing, we achieved 92.4% overall accuracy with minimal variation across demographics (see Bias Testing Report). False positives occur in 5-15% of cases depending on content type, which is why human review is mandatory.</p>
            
            <h6 class="mt-3">Q: What happens to the images?</h6>
            <p>A: Images are processed entirely in memory and immediately discarded after scanning. Only cryptographic hashes and metadata are retained for audit purposes, protecting student privacy.</p>
            
            <h6 class="mt-3">Q: How do you handle bias?</h6>
            <p>A: We tested across all Fitzpatrick skin tones with minimal accuracy variation (1.6% range). We use diverse training data, conservative thresholds, and mandatory human review to mitigate bias.</p>
            
            <h6 class="mt-3">Q: What's different about your approach?</h6>
            <p>A: Unlike automated systems, we never auto-delete content. Every flagged item requires human review, preventing false positives from harming students while maintaining safety.</p>
        </div>
    </div>

    <div class="alert alert-success mt-4">
        <i class="bi bi-check-circle-fill"></i> <strong>Ready to Record:</strong> With this plan, you're prepared to create a compelling 2-minute demo that showcases technical excellence and ethical AI principles.
    </div>

    <p class="mt-4">
        <a href="/submission" class="btn btn-outline-primary">View Submission Package</a>
        <a href="/" class="btn btn-outline-secondary">Back to Home</a>
    </p>
</div>
{% endblock %}
